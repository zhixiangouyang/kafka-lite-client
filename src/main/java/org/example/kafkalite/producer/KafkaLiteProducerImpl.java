package org.example.kafkalite.producer;

import org.example.kafkalite.core.KafkaSocketClient;
import org.example.kafkalite.metadata.MetadataManager;
import org.example.kafkalite.metadata.MetadataManagerImpl;
import org.example.kafkalite.monitor.MetricsCollector;
import org.example.kafkalite.protocol.KafkaRecordEncoder;
import org.example.kafkalite.protocol.ProduceRequestBuilder;

import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicLong;
import java.util.Collections;

public class KafkaLiteProducerImpl implements KafkaLiteProducer {
    private final Partitioner partitioner;
    private final MetadataManager metadataManager;
    private final MetricsCollector metricsCollector;
    private final BlockingQueue<ProducerRecord> recordQueue;
    private final ExecutorService senderThreadPool;
    private final AtomicBoolean closed = new AtomicBoolean(false);
    private final int batchSize;
    private final long lingerMs;
    private final int maxRetries;
    private final long retryBackoffMs;
    private final ConcurrentMap<String, KafkaSocketClient.ConnectionPool> connectionPools = new ConcurrentHashMap<>();
    private final int senderThreads;
    private final String compressionType;
    private final int poolSize;
    private final short acks;
    
    // æ–°å¢ï¼šåˆ†åŒºçº§ç¼“å­˜æœºåˆ¶
    private final ConcurrentMap<String, PartitionBatchCache> partitionCaches = new ConcurrentHashMap<>();
    private final ScheduledExecutorService cacheFlushExecutor;
    
    // åˆ†åŒºæ‰¹æ¬¡ç¼“å­˜
    private static class PartitionBatchCache {
        private final String topicPartitionKey;
        private final List<ProducerRecord> cachedRecords = new ArrayList<>();
        private volatile long firstMessageTime = 0;
        private final Object lock = new Object();
        
        public PartitionBatchCache(String topicPartitionKey) {
            this.topicPartitionKey = topicPartitionKey;
        }
        
        // æ·»åŠ æ¶ˆæ¯åˆ°ç¼“å­˜ï¼Œè¿”å›æ˜¯å¦è¾¾åˆ°å‘é€æ¡ä»¶
        public List<ProducerRecord> addAndCheckFlush(List<ProducerRecord> newRecords, int batchSizeBytes, long lingerMs) {
            synchronized (lock) {
                if (cachedRecords.isEmpty()) {
                    firstMessageTime = System.currentTimeMillis();
                }
                
                cachedRecords.addAll(newRecords);
                
                // è®¡ç®—å½“å‰æ‰¹æ¬¡çš„å­—èŠ‚å¤§å°
                int currentBatchBytes = 0;
                for (ProducerRecord record : cachedRecords) {
                    // ä¼°ç®—æ¶ˆæ¯å¤§å°ï¼škey + value + å¤´éƒ¨å¼€é”€
                    int keySize = record.getKey() != null ? record.getKey().getBytes().length : 0;
                    int valueSize = record.getValue() != null ? record.getValue().getBytes().length : 0;
                    currentBatchBytes += keySize + valueSize + 32; // 32å­—èŠ‚å¤´éƒ¨å¼€é”€ä¼°ç®—
                }
                
                // æ£€æŸ¥æ˜¯å¦éœ€è¦ç«‹å³å‘é€ï¼šå­—èŠ‚æ•°è¶…è¿‡é™åˆ¶ æˆ– æ—¶é—´è¶…è¿‡é™åˆ¶
                boolean shouldFlush = currentBatchBytes >= batchSizeBytes || 
                                    (System.currentTimeMillis() - firstMessageTime >= lingerMs);
                
                if (shouldFlush) {
                    List<ProducerRecord> toSend = new ArrayList<>(cachedRecords);
                    cachedRecords.clear();
                    firstMessageTime = 0;
                    return toSend;
                }
                
                return null; // ä¸éœ€è¦å‘é€
            }
        }
        
        // å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
        public List<ProducerRecord> forceFlush() {
            synchronized (lock) {
                if (cachedRecords.isEmpty()) {
                    return null;
                }
                
                List<ProducerRecord> toSend = new ArrayList<>(cachedRecords);
                cachedRecords.clear();
                firstMessageTime = 0;
                return toSend;
            }
        }
        
        // æ£€æŸ¥æ˜¯å¦è¶…æ—¶éœ€è¦åˆ·æ–°
        public boolean shouldTimeoutFlush(long lingerMs) {
            synchronized (lock) {
                return !cachedRecords.isEmpty() && 
                       (System.currentTimeMillis() - firstMessageTime >= lingerMs);
            }
        }
    }

    public KafkaLiteProducerImpl(List<String> bootstrapServers, Partitioner partitioner, ProducerConfig config) {
        this.partitioner = partitioner;
        this.metadataManager = new MetadataManagerImpl(bootstrapServers);
        this.metricsCollector = new MetricsCollector();
        this.batchSize = config.getBatchSize();
        this.lingerMs = config.getLingerMs();
        this.maxRetries = config.getMaxRetries();
        this.retryBackoffMs = config.getRetryBackoffMs();
        this.recordQueue = new LinkedBlockingQueue<>(config.getMaxQueueSize());
        this.compressionType = config.getCompressionType();
        this.poolSize = config.getConnectionPoolSize();
        this.acks = config.getAcks();
        
        // ä½¿ç”¨æ›´å¤šçº¿ç¨‹å‘é€æ¶ˆæ¯ï¼Œæé«˜å¹¶è¡Œåº¦
//        this.senderThreads = 18;
//        this.senderThreads = Math.max(50, Runtime.getRuntime().availableProcessors() * 4);
        this.senderThreads = Math.max(1, Runtime.getRuntime().availableProcessors() * 2);
        this.senderThreadPool = Executors.newFixedThreadPool(senderThreads,
            new ThreadFactory() {
                private final AtomicLong threadCounter = new AtomicLong(0);
                @Override
                public Thread newThread(Runnable r) {
                    Thread t = new Thread(r, "kafka-sender-" + threadCounter.incrementAndGet());
                    t.setDaemon(true);
                    return t;
                }
            });

        // åˆå§‹åŒ–ç¼“å­˜åˆ·æ–°çº¿ç¨‹æ± 
        this.cacheFlushExecutor = Executors.newSingleThreadScheduledExecutor(r -> {
            Thread t = new Thread(r, "partition-cache-flush");
            t.setDaemon(true);
            return t;
        });
        
        // å¯åŠ¨å®šæœŸåˆ·æ–°ç¼“å­˜çš„ä»»åŠ¡
        startCacheFlushTask();
        
        System.out.printf("åˆå§‹åŒ–ç”Ÿäº§è€…: å‘é€çº¿ç¨‹æ•°=%d, æ‰¹æ¬¡å¤§å°=%d, ç­‰å¾…æ—¶é—´=%dms%n", 
            senderThreads, batchSize, lingerMs);
        
        // é¢„å…ˆåˆå§‹åŒ–è¿æ¥å’Œå…ƒæ•°æ®
        for (String broker : bootstrapServers) {
            try {
                String[] parts = broker.split(":");
                String host = parts[0];
                int port = Integer.parseInt(parts[1]);
                
                // é¢„å…ˆåˆ›å»ºè¿æ¥æ± 
                KafkaSocketClient.ConnectionPool connectionPool = new KafkaSocketClient.ConnectionPool(host, port, this.poolSize);
                connectionPools.put(broker, connectionPool);
                
                System.out.printf("é¢„å…ˆåˆ›å»ºè¿æ¥æ± : %s%n", broker);
            } catch (Exception e) {
                System.err.printf("é¢„å…ˆåˆ›å»ºè¿æ¥æ± å¤±è´¥: %s, é”™è¯¯: %s%n", broker, e.getMessage());
            }
        }
            
        // å¯åŠ¨å‘é€çº¿ç¨‹
        startSenderThreads();
    }
    
    // å¯åŠ¨å®šæœŸåˆ·æ–°ç¼“å­˜çš„ä»»åŠ¡
    private void startCacheFlushTask() {
        // ç¡®ä¿delayå‚æ•°ä¸ä¸º0ï¼Œé¿å…scheduleWithFixedDelayå¼‚å¸¸
        long initialDelay = Math.max(1, lingerMs);
        long delay = Math.max(1, lingerMs / 2);
        
        cacheFlushExecutor.scheduleWithFixedDelay(() -> {
            try {
                // å®šæœŸæ£€æŸ¥æ‰€æœ‰åˆ†åŒºç¼“å­˜ï¼Œåˆ·æ–°è¶…æ—¶çš„ç¼“å­˜
                for (Map.Entry<String, PartitionBatchCache> entry : partitionCaches.entrySet()) {
                    String topicPartitionKey = entry.getKey();
                    PartitionBatchCache cache = entry.getValue();
                    
                    if (cache.shouldTimeoutFlush(lingerMs)) {
                        List<ProducerRecord> toFlush = cache.forceFlush();
                        if (toFlush != null && !toFlush.isEmpty()) {
                            // è§£ætopicå’Œpartition
                            String[] parts = topicPartitionKey.split("-");
                            if (parts.length == 2) {
                                String topic = parts[0];
                                int partition = Integer.parseInt(parts[1]);
                                
                                // å¼‚æ­¥å‘é€ï¼Œé¿å…é˜»å¡ç¼“å­˜åˆ·æ–°çº¿ç¨‹
                                senderThreadPool.submit(() -> {
                                    try {
                                        doSendPartitionBatch(topic, partition, toFlush);
                                    } catch (Exception e) {
                                        System.err.printf("ç¼“å­˜åˆ·æ–°å‘é€å¤±è´¥: topic=%s, partition=%d, é”™è¯¯=%s%n", 
                                            topic, partition, e.getMessage());
                                    }
                                });
                            }
                        }
                    }
                }
            } catch (Exception e) {
                System.err.println("ç¼“å­˜åˆ·æ–°ä»»åŠ¡å¼‚å¸¸: " + e.getMessage());
            }
        }, initialDelay, delay, TimeUnit.MILLISECONDS); // æ¯åŠä¸ªlingeræ—¶é—´æ£€æŸ¥ä¸€æ¬¡
    }

    private void startSenderThreads() {
        // å¯åŠ¨å¤šä¸ªå‘é€çº¿ç¨‹
        for (int i = 0; i < senderThreads; i++) {
            final int threadId = i;
            senderThreadPool.submit(() -> {
                System.out.printf("å‘é€çº¿ç¨‹ %d å·²å¯åŠ¨%n", threadId);
                
                while (!closed.get() || !recordQueue.isEmpty()) {
                    try {
                        // ç®€åŒ–ï¼šç›´æ¥æ‹‰å–å•æ¡æ¶ˆæ¯ï¼Œç«‹å³è¿›å…¥åˆ†åŒºç¼“å­˜
                        ProducerRecord record = recordQueue.poll(lingerMs, TimeUnit.MILLISECONDS);
                        if (record != null) {
                            // ç«‹å³å¤„ç†å•æ¡æ¶ˆæ¯ï¼Œè®©åˆ†åŒºç¼“å­˜æœºåˆ¶å†³å®šä½•æ—¶å‘é€
                            processRecord(record);
                        }
                    } catch (InterruptedException e) {
                        Thread.currentThread().interrupt();
                        System.err.printf("å‘é€çº¿ç¨‹ %d è¢«ä¸­æ–­%n", threadId);
                        break;
                    } catch (Exception e) {
                        System.err.printf("å‘é€çº¿ç¨‹ %d å‘ç”Ÿé”™è¯¯: %s%n", threadId, e.getMessage());
                        // ç»§ç»­è¿è¡Œï¼Œä¸è¦å› ä¸ºä¸€ä¸ªé”™è¯¯å°±é€€å‡ºçº¿ç¨‹
                    }
                }
                System.out.printf("å‘é€çº¿ç¨‹ %d å·²é€€å‡º%n", threadId);
            });
        }
    }
    
    // æ–°å¢ï¼šå¤„ç†å•æ¡æ¶ˆæ¯çš„æ–¹æ³•
    private void processRecord(ProducerRecord record) {
        String topic = record.getTopic();
        
        try {
            // ç¡®ä¿å…ƒæ•°æ®å·²åˆ·æ–° - ç”Ÿäº§è€…ä¸Šä¸‹æ–‡
            // å…ˆå°è¯•è·å–åˆ†åŒºä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ·æ–°å…ƒæ•°æ®
            Map<Integer, String> partitionToBroker = metadataManager.getPartitionLeaders(topic);
            if (partitionToBroker.isEmpty()) {
                metadataManager.refreshMetadata(topic, false, true);
                // åˆ·æ–°åå†æ¬¡è·å–
                partitionToBroker = metadataManager.getPartitionLeaders(topic);
            }
            
            // è·å–åˆ†åŒº
            int partitionCount = partitionToBroker.size();
            if (partitionCount == 0) {
                System.err.printf("è­¦å‘Š: topic=%s æ²¡æœ‰å¯ç”¨åˆ†åŒº%n", topic);
                return;
            }
            
            int partition = partitioner.partition(topic, record.getKey(), partitionCount);
            
            // ç›´æ¥å‘é€åˆ°åˆ†åŒºç¼“å­˜ï¼Œè®©ç¼“å­˜æœºåˆ¶å†³å®šä½•æ—¶å‘é€
            sendToPartitionCache(topic, partition, record);
            
        } catch (Exception e) {
            System.err.printf("å¤„ç†æ¶ˆæ¯å¤±è´¥: topic=%s, é”™è¯¯=%s%n", topic, e.getMessage());
            // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: æ¶ˆæ¯å¤„ç†å¤±è´¥
            metricsCollector.incrementCounter(MetricsCollector.METRIC_PRODUCER_SEND_ERROR);
        }
    }
    
    // æ–°å¢ï¼šå‘é€å•æ¡æ¶ˆæ¯åˆ°åˆ†åŒºç¼“å­˜çš„æ–¹æ³•
    private void sendToPartitionCache(String topic, int partition, ProducerRecord record) {
        String topicPartitionKey = topic + "-" + partition;
        PartitionBatchCache cache = partitionCaches.computeIfAbsent(topicPartitionKey, 
            k -> new PartitionBatchCache(k));
        
        // æ·»åŠ å•æ¡æ¶ˆæ¯åˆ°ç¼“å­˜ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦ç«‹å³å‘é€
        List<ProducerRecord> toSend = cache.addAndCheckFlush(
            Collections.singletonList(record), batchSize, lingerMs);
        
        if (toSend != null) {
            // è¾¾åˆ°å‘é€æ¡ä»¶ï¼Œç«‹å³å‘é€
            doSendPartitionBatch(topic, partition, toSend);
        }
        // å¦‚æœtoSendä¸ºnullï¼Œè¯´æ˜æ¶ˆæ¯å·²ç¼“å­˜ï¼Œç­‰å¾…åç»­è§¦å‘æˆ–è¶…æ—¶åˆ·æ–°
    }

    // ç§»é™¤åŸæ¥çš„sendPartitionBatchæ–¹æ³•ï¼Œç°åœ¨æ‰€æœ‰æ¶ˆæ¯éƒ½é€šè¿‡sendToPartitionCacheå¤„ç†
    
    // å®é™…æ‰§è¡Œåˆ†åŒºæ‰¹æ¬¡å‘é€çš„æ–¹æ³•
    private void doSendPartitionBatch(String topic, int partition, List<ProducerRecord> batch) {
        if (batch.isEmpty()) return;
        
        long startTime = System.currentTimeMillis();
        // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: è®°å½•åˆ†åŒºæ‰¹æ¬¡å‘é€å°è¯•
        Map<String, String> labels = new java.util.HashMap<>();
        labels.put("topic", topic);
        labels.put("partition", String.valueOf(partition));
        metricsCollector.incrementCounter("producer.batch.send.attempt", labels);
        try {
            // è·å–åˆ†åŒºå¯¹åº”çš„broker
            Map<Integer, String> partitionToBroker = metadataManager.getPartitionLeaders(topic);
            String brokerAddress = partitionToBroker.get(partition);
            if (brokerAddress == null) {
                System.err.printf("é”™è¯¯: æ‰¾ä¸åˆ°topic=%s, partition=%dçš„leader broker%n", topic, partition);
                throw new RuntimeException("No leader broker found for topic = " + topic + ", partition = " + partition);
            }
            
            String[] parts = brokerAddress.split(":");
            String host = parts[0];
            int port = Integer.parseInt(parts[1]);
            
            // è·å–æˆ–åˆ›å»ºè¿æ¥æ± 
            KafkaSocketClient.ConnectionPool connectionPool;
            try {
                connectionPool = connectionPools.computeIfAbsent(
                    brokerAddress, 
                    k -> new KafkaSocketClient.ConnectionPool(host, port, this.poolSize)
                );
            } catch (Exception e) {
                System.err.printf("é”™è¯¯: åˆ›å»ºè¿æ¥æ± å¤±è´¥: %s:%d, é”™è¯¯: %s%n", host, port, e.getMessage());
                throw e;
            }
            
            // æ„å»ºæ‰¹é‡æ¶ˆæ¯
            ByteBuffer recordBatch;
            try {
                recordBatch = buildRecordBatch(batch);
            } catch (Exception e) {
                System.err.printf("é”™è¯¯: æ„å»ºæ‰¹é‡æ¶ˆæ¯å¤±è´¥: %s%n", e.getMessage());
                throw e;
            }
            
            // å¦‚æœæ‰¹é‡æ¶ˆæ¯ä¸ºç©ºï¼ˆå¯èƒ½å› ä¸ºå¤§å°é™åˆ¶è¢«è¿‡æ»¤ï¼‰ï¼Œåˆ™ç›´æ¥è¿”å›
            if (recordBatch.remaining() == 0) {
                System.err.println("è­¦å‘Š: æ‰¹é‡æ¶ˆæ¯ä¸ºç©ºï¼Œå¯èƒ½æ˜¯å› ä¸ºæ¶ˆæ¯å¤§å°è¶…è¿‡é™åˆ¶ï¼Œè·³è¿‡å‘é€");
                return;
            }
            
            // æ„é€ ProduceRequest
            ByteBuffer request;
            try {
                request = ProduceRequestBuilder.build(
                        "kafka-lite",
                        topic,
                        partition,
                        recordBatch,
                        acks,  // ä½¿ç”¨é…ç½®çš„ackså‚æ•°
                        3000,
                        1
                );
            } catch (Exception e) {
                System.err.printf("é”™è¯¯: æ„å»ºProduceRequestå¤±è´¥: %s%n", e.getMessage());
                throw e;
            }
            
            // ğŸ”§ é€šè¿‡è¿æ¥æ± å‘é€ï¼Œæ·»åŠ é‡è¯•é€»è¾‘
            ByteBuffer response = null;
            Exception lastException = null;
            
            for (int retryCount = 0; retryCount <= maxRetries; retryCount++) {
                try {
                    if (retryCount > 0) {
                        System.out.printf("é‡è¯•å‘é€: topic=%s, partition=%d, ç¬¬%dæ¬¡é‡è¯•\n", topic, partition, retryCount);
                        Thread.sleep(retryBackoffMs);
                        
                        // é‡è¯•æ—¶æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°å…ƒæ•°æ®
                        metadataManager.refreshMetadata(topic, true, true);
                        Map<Integer, String> newPartitionToBroker = metadataManager.getPartitionLeaders(topic);
                        String newBrokerAddress = newPartitionToBroker.get(partition);
                        
                        if (newBrokerAddress != null && !newBrokerAddress.equals(brokerAddress)) {
                            System.out.printf("æ£€æµ‹åˆ°brokerå˜åŒ–: %s -> %s\n", brokerAddress, newBrokerAddress);
                            brokerAddress = newBrokerAddress;
                            String[] newParts = brokerAddress.split(":");
                            String newHost = newParts[0];
                            int newPort = Integer.parseInt(newParts[1]);
                            
                            connectionPool = connectionPools.computeIfAbsent(
                                brokerAddress, 
                                k -> new KafkaSocketClient.ConnectionPool(newHost, newPort, this.poolSize)
                            );
                        }
                    }
                    
                    response = connectionPool.sendAndReceive(request);
                    System.out.printf("æˆåŠŸå‘é€ %d æ¡æ¶ˆæ¯åˆ° topic=%s, partition=%d%s%n", 
                        batch.size(), topic, partition, retryCount > 0 ? " (é‡è¯•æˆåŠŸ)" : "");
                    
                    // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: æ‰¹æ¬¡å‘é€æˆåŠŸ
                    metricsCollector.incrementCounter("producer.batch.send.success", labels);
                    for (int i = 0; i < batch.size(); i++) {
                        metricsCollector.incrementCounter(MetricsCollector.METRIC_PRODUCER_SEND_SUCCESS);
                    }
                    
                    break; // æˆåŠŸåˆ™é€€å‡ºé‡è¯•å¾ªç¯
                    
                } catch (Exception e) {
                    lastException = e;
                    System.err.printf("å‘é€å¤±è´¥: topic=%s, partition=%d, é‡è¯•=%d/%d, é”™è¯¯: %s%n", 
                        topic, partition, retryCount, maxRetries, e.getMessage());
                    
                    // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: æ‰¹æ¬¡å‘é€é‡è¯•
                    labels.put("retry_count", String.valueOf(retryCount));
                    metricsCollector.incrementCounter("producer.batch.send.retry", labels);
                    
                    if (retryCount >= maxRetries) {
                        System.err.printf("å‘é€æœ€ç»ˆå¤±è´¥: topic=%s, partition=%d, å·²é‡è¯•%dæ¬¡%n", 
                            topic, partition, maxRetries);
                        
                        // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: æ‰¹æ¬¡å‘é€æœ€ç»ˆå¤±è´¥
                        metricsCollector.incrementCounter("producer.batch.send.error", labels);
                        for (int i = 0; i < batch.size(); i++) {
                            metricsCollector.incrementCounter(MetricsCollector.METRIC_PRODUCER_SEND_ERROR);
                        }
                        
                        throw new RuntimeException("å‘é€å¤±è´¥ï¼Œå·²é‡è¯•" + maxRetries + "æ¬¡", lastException);
                    }
                }
            }
            
            // è¿™é‡Œå¯ä»¥è§£æå“åº”ï¼Œå¤„ç†é”™è¯¯ç­‰
            
        } catch (Exception e) {
            // å‘ç”Ÿé”™è¯¯ï¼Œå°è¯•é‡è¯•
            int retries = 0;
            boolean interrupted = false;
            while (retries < maxRetries && !interrupted) {
                try {
                    Thread.sleep(retryBackoffMs);
                    // åˆ·æ–°å…ƒæ•°æ® - ç”Ÿäº§è€…é‡è¯•ï¼Œé”™è¯¯è§¦å‘
                    metadataManager.refreshMetadata(topic, true, true);
                    System.out.printf("é‡è¯•å‘é€æ¶ˆæ¯ (ç¬¬%dæ¬¡): topic=%s, partition=%d%n", 
                        retries + 1, topic, partition);
                    // é‡è¯•æ—¶ç›´æ¥å‘é€ï¼Œè·³è¿‡ç¼“å­˜æœºåˆ¶
                    doSendPartitionBatch(topic, partition, batch);
                    return; // å¦‚æœé‡è¯•æˆåŠŸï¼Œç›´æ¥è¿”å›
                } catch (InterruptedException ie) {
                    // å¤„ç†ä¸­æ–­å¼‚å¸¸
                    Thread.currentThread().interrupt();
                    interrupted = true;
                    System.err.println("å‘é€çº¿ç¨‹è¢«ä¸­æ–­");
                } catch (Exception retryEx) {
                    retries++;
                    System.err.printf("é‡è¯•å¤±è´¥ (ç¬¬%dæ¬¡): topic=%s, partition=%d, é”™è¯¯: %s%n", 
                        retries, topic, partition, retryEx.getMessage());
                    if (retries >= maxRetries) {
                        System.err.println("æ‰¹é‡å‘é€å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: " + retryEx.getMessage());
                    }
                }
            }
        } finally {
            long endTime = System.currentTimeMillis();
            long totalLatency = endTime - startTime;
            
            // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: è®°å½•æ‰¹æ¬¡å‘é€å»¶è¿Ÿ
            metricsCollector.recordLatency("producer.batch.send.latency", totalLatency, labels);
            
            // ğŸ”§ ä¿®æ­£ï¼šåˆ†åˆ«ç»Ÿè®¡ä¸¤ç§å»¶è¿Ÿ
            for (ProducerRecord record : batch) {
                // 1. çœŸå®ç«¯åˆ°ç«¯å»¶è¿Ÿï¼šä»æ¶ˆæ¯åˆ›å»ºåˆ°å“åº”æ¥æ”¶ï¼ˆåŒ…å«é˜Ÿåˆ—ç­‰å¾…æ—¶é—´ï¼‰
                if (record.getSendTimestamp() > 0) {
                    long endToEndLatency = endTime - record.getSendTimestamp();
                    metricsCollector.recordLatency("producer.end_to_end.latency", endToEndLatency);
                }
                
                // 2. ç½‘ç»œå‘é€å»¶è¿Ÿï¼šä»å¼€å§‹å‘é€åˆ°å“åº”æ¥æ”¶ï¼ˆä¸åŒ…å«é˜Ÿåˆ—ç­‰å¾…ï¼‰
                metricsCollector.recordLatency(MetricsCollector.METRIC_PRODUCER_SEND, totalLatency);
            }
        }
    }
    
    private ByteBuffer buildRecordBatch(List<ProducerRecord> records) {
        // æš‚æ—¶ä½¿ç”¨æ— å‹ç¼©çš„æ‰¹é‡ç¼–ç ï¼Œé¿å…ç¼–ç é—®é¢˜
        if ("none".equals(compressionType) || compressionType == null) {
            return KafkaRecordEncoder.encodeBatchMessagesOptimized(records);
        } else {
            // å‹ç¼©ç‰ˆæœ¬ï¼ˆä¿®å¤åï¼‰
            return KafkaRecordEncoder.encodeBatchMessagesOptimized(records, compressionType);
        }
    }

    private void doSend(ProducerRecord record) throws Exception {
        String topic = record.getTopic();
        String key = record.getKey();
        String value = record.getValue();

        // 1. åˆ·æ–°å…ƒæ•°æ®ï¼ˆè‹¥å·²å­˜åœ¨å¯å†…éƒ¨è·³è¿‡ï¼‰- ç”Ÿäº§è€…ä¸Šä¸‹æ–‡
        metadataManager.refreshMetadata(topic, false, true);

        // 2. è·å–partition -> broker æ˜ å°„
        Map<Integer, String> partitionToBroker = metadataManager.getPartitionLeaders(topic);
        int partitionCount = partitionToBroker.size();

        if (partitionCount == 0) {
            throw new RuntimeException("No partition found for topic: " + topic);
        }

        // 3. ä½¿ç”¨åˆ†åŒºå™¨å†³å®šå‘é€åˆ°å“ªä¸ªåˆ†åŒº
        int partition = partitioner.partition(topic, key, partitionCount);

        // 4. è·å– partition å¯¹åº”çš„ broker
        String brokerAddress = partitionToBroker.get(partition);
        if (brokerAddress == null) {
            throw new RuntimeException("No leader broker found for topic = " + topic + ", partition = " + partition);
        }

        String[] parts = brokerAddress.split(":");
        String host = parts[0];
        int port = Integer.parseInt(parts[1]);
        
        // è·å–æˆ–åˆ›å»ºè¿æ¥æ± 
        KafkaSocketClient.ConnectionPool connectionPool = connectionPools.computeIfAbsent(
            brokerAddress, 
            k -> new KafkaSocketClient.ConnectionPool(host, port, this.poolSize)
        );

        // 5. æ„é€  RecordBatchï¼ˆKafkaåè®®æ ‡å‡†æ ¼å¼ï¼‰
        ByteBuffer recordBatch = KafkaRecordEncoder.encodeRecordBatch(key, value);

        // 6. æ„é€ ProduceRequestï¼ˆåŒ…å«header + bodyï¼‰
        ByteBuffer request = ProduceRequestBuilder.build(
                "kafka-lite",
                topic,
                partition,
                recordBatch,
                acks,  // ä½¿ç”¨é…ç½®çš„ackså‚æ•°
                3000,
                1
        );

        // ğŸ”§ 7. é€šè¿‡è¿æ¥æ± å‘é€ï¼Œæ·»åŠ é‡è¯•é€»è¾‘
        Exception lastException = null;
        for (int retryCount = 0; retryCount <= maxRetries; retryCount++) {
            try {
                if (retryCount > 0) {
                    System.out.printf("é‡è¯•å‘é€å•æ¡æ¶ˆæ¯: topic=%s, partition=%d, ç¬¬%dæ¬¡é‡è¯•\n", topic, partition, retryCount);
                    Thread.sleep(retryBackoffMs);
                    
                    // é‡è¯•æ—¶åˆ·æ–°å…ƒæ•°æ®
                    metadataManager.refreshMetadata(topic, true, true);
                }
                
                connectionPool.sendAndReceive(request);
                if (retryCount > 0) {
                    System.out.printf("å•æ¡æ¶ˆæ¯é‡è¯•å‘é€æˆåŠŸ: topic=%s, partition=%d\n", topic, partition);
                }
                break; // æˆåŠŸåˆ™é€€å‡ºé‡è¯•å¾ªç¯
                
            } catch (Exception e) {
                lastException = e;
                System.err.printf("å•æ¡æ¶ˆæ¯å‘é€å¤±è´¥: topic=%s, partition=%d, é‡è¯•=%d/%d, é”™è¯¯: %s\n", 
                    topic, partition, retryCount, maxRetries, e.getMessage());
                
                if (retryCount >= maxRetries) {
                    throw new RuntimeException("å•æ¡æ¶ˆæ¯å‘é€å¤±è´¥ï¼Œå·²é‡è¯•" + maxRetries + "æ¬¡", lastException);
                }
            }
        }
    }

    @Override
    public void send(ProducerRecord record) {
        if (closed.get()) {
            throw new IllegalStateException("Cannot send after the producer is closed");
        }

        long startTime = System.currentTimeMillis();
        try {
            // æ·»åŠ èƒŒå‹æœºåˆ¶ï¼šå¦‚æœé˜Ÿåˆ—å·²æ»¡è¶…è¿‡90%ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´
            while (recordQueue.size() > recordQueue.remainingCapacity() * 9) {
                Thread.sleep(1);
            }
            
            // ä½¿ç”¨è¶…æ—¶ç‰ˆæœ¬çš„offerï¼Œé¿å…æ— é™ç­‰å¾…
            if (!recordQueue.offer(record, lingerMs, TimeUnit.MILLISECONDS)) {
                System.err.println("è­¦å‘Š: å‘é€ç¼“å†²åŒºå·²æ»¡ï¼Œæ¶ˆæ¯è¢«ä¸¢å¼ƒ");
                // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: é˜Ÿåˆ—æ»¡é”™è¯¯
                metricsCollector.incrementCounter(MetricsCollector.METRIC_PRODUCER_SEND_ERROR);
                throw new RuntimeException("Send buffer is full");
            }
            
            // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: å¼‚æ­¥å‘é€æˆåŠŸå…¥é˜Ÿ
            metricsCollector.incrementCounter("producer.send.queued");
            
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: ä¸­æ–­é”™è¯¯
            metricsCollector.incrementCounter(MetricsCollector.METRIC_PRODUCER_SEND_ERROR);
            throw new RuntimeException("Interrupted while adding record to queue", e);
        } finally {
            // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: è®°å½•å…¥é˜Ÿå»¶è¿Ÿ
            long latency = System.currentTimeMillis() - startTime;
            metricsCollector.recordLatency("producer.send.queue_latency", latency);
        }
    }

    @Override
    public void sendSync(ProducerRecord record) throws Exception {
        if (closed.get()) {
            throw new IllegalStateException("Cannot send after the producer is closed");
        }

        long startTime = System.currentTimeMillis();
        try {
        // ç›´æ¥è°ƒç”¨ç°æœ‰çš„doSendæ–¹æ³•è¿›è¡ŒåŒæ­¥å‘é€
        doSend(record);
            
            // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: åŒæ­¥å‘é€æˆåŠŸ
            metricsCollector.incrementCounter(MetricsCollector.METRIC_PRODUCER_SEND_SUCCESS);
            
        } catch (Exception e) {
            // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: åŒæ­¥å‘é€å¤±è´¥
            metricsCollector.incrementCounter(MetricsCollector.METRIC_PRODUCER_SEND_ERROR);
            throw e;
        } finally {
            // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: è®°å½•åŒæ­¥å‘é€æ€»å»¶è¿Ÿ
            long latency = System.currentTimeMillis() - startTime;
            metricsCollector.recordLatency(MetricsCollector.METRIC_PRODUCER_SEND, latency);
        }
    }

    @Override
    public void flush() {
        // ç­‰å¾…é˜Ÿåˆ—æ¸…ç©º
        while (!recordQueue.isEmpty()) {
            try {
                Thread.sleep(100);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                throw new RuntimeException("Interrupted while flushing", e);
            }
        }
    }

    @Override
    public void close() {
        if (closed.compareAndSet(false, true)) {
            try {
                // æ–°å¢ï¼šåˆ·æ–°æ‰€æœ‰åˆ†åŒºç¼“å­˜ä¸­çš„æ¶ˆæ¯
                System.out.println("æ­£åœ¨åˆ·æ–°åˆ†åŒºç¼“å­˜...");
                for (Map.Entry<String, PartitionBatchCache> entry : partitionCaches.entrySet()) {
                    String topicPartitionKey = entry.getKey();
                    PartitionBatchCache cache = entry.getValue();
                    
                    List<ProducerRecord> toFlush = cache.forceFlush();
                    if (toFlush != null && !toFlush.isEmpty()) {
                        // è§£ætopicå’Œpartition
                        String[] parts = topicPartitionKey.split("-");
                        if (parts.length == 2) {
                            String topic = parts[0];
                            int partition = Integer.parseInt(parts[1]);
                            
                            System.out.printf("åˆ·æ–°ç¼“å­˜: topic=%s, partition=%d, æ¶ˆæ¯æ•°=%d%n", 
                                topic, partition, toFlush.size());
                            
                            try {
                                doSendPartitionBatch(topic, partition, toFlush);
                            } catch (Exception e) {
                                System.err.printf("åˆ·æ–°ç¼“å­˜å¤±è´¥: topic=%s, partition=%d, é”™è¯¯=%s%n", 
                                    topic, partition, e.getMessage());
                            }
                        }
                    }
                }
                partitionCaches.clear();
                
                // ç­‰å¾…æ‰€æœ‰æ¶ˆæ¯å‘é€å®Œæˆ
                while (!recordQueue.isEmpty()) {
                    try {
                        Thread.sleep(100);
                    } catch (InterruptedException e) {
                        Thread.currentThread().interrupt();
                        break;
                    }
                }

                // å…³é—­ç¼“å­˜åˆ·æ–°çº¿ç¨‹æ± 
                if (cacheFlushExecutor != null) {
                    cacheFlushExecutor.shutdown();
                    try {
                        if (!cacheFlushExecutor.awaitTermination(2000, TimeUnit.MILLISECONDS)) {
                            cacheFlushExecutor.shutdownNow();
                        }
                    } catch (InterruptedException e) {
                        cacheFlushExecutor.shutdownNow();
                    }
                }

                // å…³é—­å‘é€çº¿ç¨‹æ± 
                senderThreadPool.shutdown();

                try {
                    if (!senderThreadPool.awaitTermination(5000, TimeUnit.MILLISECONDS)) {
                        senderThreadPool.shutdownNow();
                    }
                } catch (InterruptedException e) {
                    senderThreadPool.shutdownNow();
                }
                
                // å…³é—­æ‰€æœ‰è¿æ¥æ± 
                for (KafkaSocketClient.ConnectionPool pool : connectionPools.values()) {
                    pool.close();
                }
                
            } finally {
                recordQueue.clear();
            }
        }
    }

    // è·å–ç”Ÿäº§è€…ç›‘æ§æŒ‡æ ‡
    public double getProducerQPS() {
        return metricsCollector.getQPS(MetricsCollector.METRIC_PRODUCER_SEND);
    }

    public double getProducerP99Latency() {
        return metricsCollector.getP99Latency(MetricsCollector.METRIC_PRODUCER_SEND);
    }
    
    // æ–°å¢ï¼šæ‰©å±•å»¶è¿ŸæŒ‡æ ‡
    public double getProducerP50Latency() {
        return metricsCollector.getP50Latency(MetricsCollector.METRIC_PRODUCER_SEND);
    }
    
    public double getProducerP95Latency() {
        return metricsCollector.getP95Latency(MetricsCollector.METRIC_PRODUCER_SEND);
    }
    
    public double getProducerP999Latency() {
        return metricsCollector.getP999Latency(MetricsCollector.METRIC_PRODUCER_SEND);
    }
    
    public double getProducerAvgLatency() {
        return metricsCollector.getAverageLatency(MetricsCollector.METRIC_PRODUCER_SEND);
    }
    
    public double getProducerMaxLatency() {
        return metricsCollector.getMaxLatency(MetricsCollector.METRIC_PRODUCER_SEND);
    }
    
    public double getProducerMinLatency() {
        return metricsCollector.getMinLatency(MetricsCollector.METRIC_PRODUCER_SEND);
    }
    
    // è·å–å½“å‰é˜Ÿåˆ—å¤§å°
    public int getQueueSize() {
        return recordQueue.size();
    }
    
    /**
     * ğŸ”§ æ–°å¢ï¼šæ¸…ç†æ‰€æœ‰è¿æ¥æ± ï¼Œç”¨äºè§£å†³è¿æ¥æ³„æ¼é—®é¢˜
     */
    public void clearAllConnectionPools() {
        System.out.println("[Producer] å¼ºåˆ¶æ¸…ç†æ‰€æœ‰è¿æ¥æ± ...");
        
        int poolCount = connectionPools.size();
        for (Map.Entry<String, KafkaSocketClient.ConnectionPool> entry : connectionPools.entrySet()) {
            String broker = entry.getKey();
            KafkaSocketClient.ConnectionPool pool = entry.getValue();
            try {
                pool.close();
                System.out.printf("[Producer] å·²å…³é—­è¿æ¥æ± : %s\n", broker);
            } catch (Exception e) {
                System.err.printf("[Producer] å…³é—­è¿æ¥æ± å¤±è´¥: %s, é”™è¯¯: %s\n", broker, e.getMessage());
            }
        }
        connectionPools.clear();
        
        // æ¸…ç†åˆ†åŒºç¼“å­˜
        partitionCaches.clear();
        
        System.out.printf("[Producer] è¿æ¥æ± æ¸…ç†å®Œæˆï¼Œå…±æ¸…ç†äº† %d ä¸ªè¿æ¥æ± \n", poolCount);
    }
    
    /**
     * ğŸ”§ æ–°å¢ï¼šè·å–è¿æ¥æ± çŠ¶æ€ä¿¡æ¯ï¼Œç”¨äºè°ƒè¯•
     */
    public void printConnectionPoolStatus() {
        System.out.println("=== Producerè¿æ¥æ± çŠ¶æ€ ===");
        for (Map.Entry<String, KafkaSocketClient.ConnectionPool> entry : connectionPools.entrySet()) {
            String broker = entry.getKey();
            System.out.printf("è¿æ¥æ± : %s\n", broker);
        }
        System.out.printf("æ€»è¿æ¥æ± æ•°: %d\n", connectionPools.size());
        System.out.println("========================");
    }
}
