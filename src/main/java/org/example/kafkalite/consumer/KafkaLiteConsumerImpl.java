package org.example.kafkalite.consumer;

import org.example.kafkalite.metadata.MetadataManager;
import org.example.kafkalite.metadata.MetadataManagerImpl;
import org.example.kafkalite.monitor.MetricsCollector;
import org.example.kafkalite.protocol.FetchRequestBuilder;
import org.example.kafkalite.protocol.FetchResponseParser;
import org.example.kafkalite.protocol.SyncGroupResponseParser;
import org.example.kafkalite.core.KafkaSocketClient;

import java.nio.ByteBuffer;
import java.util.*;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;

public class KafkaLiteConsumerImpl implements KafkaLiteConsumer {
    private volatile List<String> bootstrapServers;  // æ”¹ä¸ºvolatileï¼Œæ”¯æŒDNSé‡è§£æåæ›´æ–°
    private final String groupId;
    private final String clientId;
    private final MetadataManager metadataManager;
    private final OffsetManager offsetManager;
    private final ConsumerConfig config;
    private final MetricsCollector metricsCollector;
    private final ConsumerCoordinator coordinator;
    private List<String> subscribedTopics = new ArrayList<>();
    private final Map<String, Map<Integer, String>> topicPartitionLeaders = new HashMap<>();
    private final AtomicBoolean closed = new AtomicBoolean(false);
    
    // æ–°å¢ï¼šå®šæœŸå…ƒæ•°æ®åˆ·æ–°ç›¸å…³
    private ScheduledExecutorService metadataRefreshExecutor;
    private final AtomicBoolean metadataRefreshStarted = new AtomicBoolean(false);
    
    public KafkaLiteConsumerImpl(String groupId, List<String> bootstrapServers, ConsumerConfig config) {
        this.groupId = groupId;
        this.bootstrapServers = bootstrapServers;
        this.config = config;
        // ä¿®å¤ï¼šä½¿ç”¨åŸºäºgroupIdçš„å›ºå®šclientIdï¼Œç¡®ä¿offsetæŒä¹…åŒ–
        this.clientId = "kafka-lite-" + groupId.replaceAll("[^a-zA-Z0-9-]", "-");
        
        // ä½¿ç”¨é…ç½®çš„è¿æ¥æ± å¤§å°åˆ›å»ºMetadataManager
        this.metadataManager = new MetadataManagerImpl(bootstrapServers, config.getMetadataConnectionPoolSize());
        this.offsetManager = new OffsetManager(groupId, bootstrapServers);
        this.metricsCollector = new MetricsCollector();
        this.coordinator = new ConsumerCoordinator(clientId, groupId, config, bootstrapServers);
        // å…±äº« MetadataManagerï¼Œé¿å…é‡å¤åˆ›å»ºè¿æ¥æ± 
        this.coordinator.setMetadataManager(this.metadataManager);
        this.offsetManager.setCoordinator(this.coordinator);
        // coordinatorSocketåœ¨coordinator.initializeGroup()åæ‰ä¼šè¢«åˆ›å»º
    }
    
    /**
     * æ–°å¢ï¼šæ”¯æŒåŸŸåçš„æ„é€ å‡½æ•°
     * æ”¯æŒä¼ å…¥åŸŸå:ç«¯å£å½¢å¼ï¼Œè‡ªåŠ¨è§£æä¸ºå¤šä¸ªIPåœ°å€
     */
    public KafkaLiteConsumerImpl(String groupId, String domainWithPort, ConsumerConfig config) {
        this.groupId = groupId;
        this.config = config;
        // ä¿®å¤ï¼šä½¿ç”¨åŸºäºgroupIdçš„å›ºå®šclientIdï¼Œç¡®ä¿offsetæŒä¹…åŒ–
        this.clientId = "kafka-lite-" + groupId.replaceAll("[^a-zA-Z0-9-]", "-");
        
        // è§£æåŸŸåä¸ºIPåˆ—è¡¨
        this.bootstrapServers = resolveDomainToIPs(domainWithPort);
        System.out.printf("[KafkaLiteConsumerImpl] åŸŸå %s è§£æåˆ° %d ä¸ªIP: %s\n", 
            domainWithPort, bootstrapServers.size(), bootstrapServers);
        
        // ä½¿ç”¨é…ç½®çš„è¿æ¥æ± å¤§å°åˆ›å»ºæ”¯æŒåŠ¨æ€DNSçš„MetadataManager
        this.metadataManager = new MetadataManagerImpl(bootstrapServers, config.getMetadataConnectionPoolSize(), domainWithPort);
        this.offsetManager = new OffsetManager(groupId, bootstrapServers);
        this.metricsCollector = new MetricsCollector();
        this.coordinator = new ConsumerCoordinator(clientId, groupId, config, bootstrapServers);
        // å…±äº« MetadataManagerï¼Œé¿å…é‡å¤åˆ›å»ºè¿æ¥æ± 
        this.coordinator.setMetadataManager(this.metadataManager);
        this.offsetManager.setCoordinator(this.coordinator);
        
        // ğŸ”§ è®¾ç½®bootstrap serverså˜åŒ–å›è°ƒï¼Œå¤„ç†DNSé‡è§£æåçš„è¿æ¥æ›´æ–°
        if (this.metadataManager instanceof MetadataManagerImpl) {
            ((MetadataManagerImpl) this.metadataManager).setBootstrapServersChangedCallback(() -> {
                handleBootstrapServersChanged();
            });
        }
        // coordinatorSocketåœ¨coordinator.initializeGroup()åæ‰ä¼šè¢«åˆ›å»º
    }
    
    /**
     * è§£æåŸŸåä¸ºIPåœ°å€åˆ—è¡¨
     */
    private List<String> resolveDomainToIPs(String domainWithPort) {
        List<String> ips = new ArrayList<>();
        
        String[] parts = domainWithPort.split(":");
        if (parts.length != 2) {
            throw new IllegalArgumentException("åŸŸåæ ¼å¼é”™è¯¯ï¼Œåº”ä¸º domain:portï¼Œå®é™…: " + domainWithPort);
        }
        
        String domain = parts[0];
        String port = parts[1];
        
        // å¦‚æœå·²ç»æ˜¯IPåœ°å€ï¼Œç›´æ¥è¿”å›
        if (isIpAddress(domain)) {
            ips.add(domainWithPort);
            return ips;
        }
        
        try {
            java.net.InetAddress[] addresses = java.net.InetAddress.getAllByName(domain);
            for (java.net.InetAddress address : addresses) {
                String ip = address.getHostAddress();
                ips.add(ip + ":" + port);
                System.out.printf("[KafkaLiteConsumerImpl] DNSè§£æ: %s -> %s:%s\n", domain, ip, port);
            }
            
            if (ips.isEmpty()) {
                throw new RuntimeException("åŸŸåè§£æå¤±è´¥ï¼Œæœªè·å–åˆ°ä»»ä½•IP: " + domain);
            }
            
        } catch (java.net.UnknownHostException e) {
            throw new RuntimeException("åŸŸåè§£æå¤±è´¥: " + domain + ", é”™è¯¯: " + e.getMessage(), e);
        }
        
        return ips;
    }
    
    /**
     * æ£€æŸ¥æ˜¯å¦ä¸ºIPåœ°å€
     */
    private boolean isIpAddress(String host) {
        String ipPattern = "^([0-9]{1,3}\\.){3}[0-9]{1,3}$";
        return host.matches(ipPattern);
    }
    
    /**
     * å¤„ç†bootstrap serverså˜åŒ–ï¼ˆDNSé‡è§£æåï¼‰
     * æ›´æ–°æ‰€æœ‰ç›¸å…³ç»„ä»¶çš„è¿æ¥
     */
    private void handleBootstrapServersChanged() {
        try {
            System.out.println("[KafkaLiteConsumerImpl] å¼€å§‹å¤„ç†bootstrap serverså˜åŒ–...");
            
            // 1. è·å–æ–°çš„bootstrap servers
            List<String> newBootstrapServers = ((MetadataManagerImpl) metadataManager).getBootstrapServers();
            System.out.printf("[KafkaLiteConsumerImpl] æ–°çš„bootstrap servers: %s\n", newBootstrapServers);
            
            // 2. æ›´æ–°æœ¬åœ°bootstrap servers
            this.bootstrapServers = newBootstrapServers;
            
            // 3. æ¸…ç©ºpartition leaderç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°è·å–
            topicPartitionLeaders.clear();
            System.out.println("[KafkaLiteConsumerImpl] å·²æ¸…ç©ºpartition leaderç¼“å­˜");
            
            // 4. TODO: é€šçŸ¥ConsumerCoordinatoræ›´æ–°bootstrap servers  
            // coordinator.updateBootstrapServers(newBootstrapServers); // éœ€è¦å®ç°æ­¤æ–¹æ³•
            
            // 5. TODO: é€šçŸ¥OffsetManageræ›´æ–°bootstrap servers
            // offsetManager.updateBootstrapServers(newBootstrapServers); // éœ€è¦å®ç°æ­¤æ–¹æ³•
            
            // ä¸´æ—¶è§£å†³ï¼šé‡æ–°åˆ›å»ºcoordinatorè¿æ¥ï¼ˆåœ¨ä¸‹æ¬¡é‡è¿æ—¶ä¼šä½¿ç”¨æ–°çš„bootstrap serversï¼‰
            System.out.println("[KafkaLiteConsumerImpl] æ³¨æ„ï¼šcoordinatorå’ŒoffsetManagerå°†åœ¨ä¸‹æ¬¡æ“ä½œæ—¶è‡ªåŠ¨ä½¿ç”¨æ–°çš„bootstrap servers");
            
            // 6. è§¦å‘metadataåˆ·æ–°ï¼Œè·å–æ–°çš„partition leaderä¿¡æ¯
            for (String topic : subscribedTopics) {
                try {
                    metadataManager.refreshMetadata(topic, true, false); // error-triggered refresh
                    Map<Integer, String> leaders = metadataManager.getPartitionLeaders(topic);
                    topicPartitionLeaders.put(topic, leaders);
                    System.out.printf("[KafkaLiteConsumerImpl] å·²æ›´æ–°topic %s çš„partition leaders: %s\n", topic, leaders);
                } catch (Exception e) {
                    System.err.printf("[KafkaLiteConsumerImpl] æ›´æ–°topic %s metadataå¤±è´¥: %s\n", topic, e.getMessage());
                }
            }
            
            System.out.println("[KafkaLiteConsumerImpl] bootstrap serverså˜åŒ–å¤„ç†å®Œæˆ");
            
        } catch (Exception e) {
            System.err.printf("[KafkaLiteConsumerImpl] å¤„ç†bootstrap serverså˜åŒ–å¤±è´¥: %s\n", e.getMessage());
        }
    }

    @Override
    public void subscribe(List<String> topics) {
        this.subscribedTopics = new ArrayList<>(topics);  // åˆ›å»ºå¯å˜å‰¯æœ¬
        
        // åˆ·æ–°å…ƒæ•°æ®
        for (String topic : topics) {
            // åˆå§‹åŒ–æ—¶åˆ·æ–°å…ƒæ•°æ® - æ­£å¸¸æƒ…å†µ
            metadataManager.refreshMetadata(topic, false, false);
            topicPartitionLeaders.put(topic, metadataManager.getPartitionLeaders(topic));
        }
        
        // åˆå§‹åŒ–æ¶ˆè´¹è€…ç»„
        coordinator.initializeGroup(topics);
        // æ–°å¢ï¼šè·å–åˆ†åŒºåˆ—è¡¨å¹¶æ‹‰å– group offset topic ->
        Map<String, List<Integer>> topicPartitions = new HashMap<>();
        for (String topic : topics) {
            Map<Integer, String> leaders = topicPartitionLeaders.get(topic);
            if (leaders != null) {
                topicPartitions.put(topic, new ArrayList<>(leaders.keySet()));
            }
        }
        offsetManager.fetchCommittedOffsets(topics, topicPartitions);
        
        // æ–°å¢ï¼šå¯åŠ¨å®šæœŸå…ƒæ•°æ®åˆ·æ–°
        startPeriodicMetadataRefresh();
    }
    
    // æ–°å¢ï¼šå¯åŠ¨å®šæœŸå…ƒæ•°æ®åˆ·æ–°
    private void startPeriodicMetadataRefresh() {
        if (!config.isEnablePeriodicMetadataRefresh()) {
            System.out.println("[KafkaLiteConsumerImpl] å®šæœŸå…ƒæ•°æ®åˆ·æ–°å·²ç¦ç”¨");
            return;
        }
        
        if (metadataRefreshStarted.compareAndSet(false, true)) {
            metadataRefreshExecutor = Executors.newSingleThreadScheduledExecutor(r -> {
                Thread t = new Thread(r, "metadata-refresh-" + clientId);
                t.setDaemon(true);
                return t;
            });
            
            long intervalMs = config.getMetadataRefreshIntervalMs();
            System.out.printf("[KafkaLiteConsumerImpl] å¯åŠ¨å®šæœŸå…ƒæ•°æ®åˆ·æ–°: é—´éš”=%dms, å®¢æˆ·ç«¯=%s\n", intervalMs, clientId);
            
            metadataRefreshExecutor.scheduleAtFixedRate(() -> {
                try {
                    if (closed.get()) {
                        return;
                    }
                    
                    System.out.printf("[KafkaLiteConsumerImpl] æ‰§è¡Œå®šæœŸå…ƒæ•°æ®åˆ·æ–°: å®¢æˆ·ç«¯=%s, topics=%s\n", clientId, subscribedTopics);
                    
                    // åˆ·æ–°æ‰€æœ‰è®¢é˜…çš„topicçš„å…ƒæ•°æ®
                    for (String topic : subscribedTopics) {
                        try {
                            // å®šæœŸåˆ·æ–°å…ƒæ•°æ® - æ­£å¸¸æƒ…å†µ
                            metadataManager.refreshMetadata(topic, false, false);
                            Map<Integer, String> leaders = metadataManager.getPartitionLeaders(topic);
                            topicPartitionLeaders.put(topic, leaders);
                            
                            System.out.printf("[KafkaLiteConsumerImpl] å®šæœŸåˆ·æ–°å®Œæˆ: topic=%s, leaders=%s\n", topic, leaders);
                        } catch (Exception e) {
                            System.err.printf("[KafkaLiteConsumerImpl] å®šæœŸåˆ·æ–°å…ƒæ•°æ®å¤±è´¥: topic=%s, é”™è¯¯=%s\n", topic, e.getMessage());
                        }
                    }
                    
                } catch (Exception e) {
                    System.err.printf("[KafkaLiteConsumerImpl] å®šæœŸå…ƒæ•°æ®åˆ·æ–°å¼‚å¸¸: å®¢æˆ·ç«¯=%s, é”™è¯¯=%s\n", clientId, e.getMessage());
                }
            }, intervalMs, intervalMs, TimeUnit.MILLISECONDS);
            
            System.out.printf("[KafkaLiteConsumerImpl] å®šæœŸå…ƒæ•°æ®åˆ·æ–°å·²å¯åŠ¨: å®¢æˆ·ç«¯=%s\n", clientId);
        }
    }
    
    // æ–°å¢ï¼šåœæ­¢å®šæœŸå…ƒæ•°æ®åˆ·æ–°
    private void stopPeriodicMetadataRefresh() {
        if (metadataRefreshExecutor != null) {
            System.out.printf("[KafkaLiteConsumerImpl] åœæ­¢å®šæœŸå…ƒæ•°æ®åˆ·æ–°: å®¢æˆ·ç«¯=%s\n", clientId);
            metadataRefreshExecutor.shutdown();
            try {
                if (!metadataRefreshExecutor.awaitTermination(5, TimeUnit.SECONDS)) {
                    metadataRefreshExecutor.shutdownNow();
                }
            } catch (InterruptedException e) {
                metadataRefreshExecutor.shutdownNow();
                Thread.currentThread().interrupt();
            }
            metadataRefreshExecutor = null;
        }
    }

    @Override
    public List<ConsumerRecord> poll(long timeoutMs) {
        if (closed.get()) {
            throw new IllegalStateException("Consumer is closed");
        }
        long startTime = System.currentTimeMillis();
        List<ConsumerRecord> allRecords = new ArrayList<>();
        
        // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: pollè°ƒç”¨è®¡æ•°
        metricsCollector.incrementCounter("consumer.poll.attempt");
        
        System.out.println("[Poll] å¼€å§‹æ‹‰å–æ¶ˆæ¯...");
        List<PartitionAssignment> assignments = coordinator.getAssignments();
        System.out.printf("[Poll] å½“å‰åˆ†åŒºåˆ†é…: %s, coordinator.isStable()=%s, coordinator.isRejoining()=%s\n", 
            assignments, coordinator.isStable(), coordinator.isRejoining());
        System.out.printf("[DEBUG] Poll check - clientId=%s, groupId=%s, memberId=%s, generationId=%d\n", 
            clientId, groupId, coordinator.getMemberId(), coordinator.getGenerationId());
        try {
            if (assignments == null || assignments.isEmpty()) {
                System.out.println("[Poll] å½“å‰æ— åˆ†åŒºåˆ†é…ï¼Œç­‰å¾…åˆ†é…å˜æ›´...");
                synchronized (coordinator.assignmentLock) {
                    coordinator.assignmentLock.wait(timeoutMs > 0 ? timeoutMs : 2000);
                }
                // å†æ¬¡è·å–åˆ†é…
                assignments = coordinator.getAssignments();
                System.out.printf("[Poll] ç­‰å¾…ååˆ†åŒºåˆ†é…: %s\n", assignments);
                if (assignments == null || assignments.isEmpty()) {
                    System.out.println("[Poll] ç­‰å¾…åä»æ— åˆ†åŒºåˆ†é…ï¼Œè¿”å›ç©ºç»“æœ");
                    return allRecords;
                }
            }
            for (PartitionAssignment assignment : assignments) {
                if (allRecords.size() >= config.getMaxPollRecords()) {
                    break;
                }
                String topic = assignment.getTopic();
                int partition = assignment.getPartition();
                Map<Integer, String> partitionLeaders = topicPartitionLeaders.get(topic);
                if (partitionLeaders == null) continue;
                String broker = partitionLeaders.get(partition);
                if (broker == null) continue;
                String[] parts = broker.split(":");
                String host = parts[0];
                int port = Integer.parseInt(parts[1]);
                long offset = offsetManager.getOffset(topic, partition);
                int retryCount = 0;
                while (retryCount < config.getMaxRetries()) {
                    try {
                        System.out.printf("[Poll] æ‹‰å–å‚æ•°: topic=%s, partition=%d, offset=%d, broker=%s:%d%n",
                            topic, partition, offset, host, port);

                        ByteBuffer fetchRequest = FetchRequestBuilder.build(
                            clientId,
                            topic,
                            partition,
                            offset,
                            config.getFetchMaxBytes(),
                            1
                        );
                        ByteBuffer response = KafkaSocketClient.sendAndReceive(host, port, fetchRequest);
                        List<ConsumerRecord> records = FetchResponseParser.parse(response);
                        if (!records.isEmpty()) {
                            long firstOffset = records.get(0).getOffset();
                            long lastOffset = records.get(records.size() - 1).getOffset();
                            System.out.printf("[Poll] æ‹‰å–åˆ°%dæ¡æ¶ˆæ¯, offsetèŒƒå›´: [%d, %d]\n", records.size(), firstOffset, lastOffset);
                            System.out.printf("[DEBUG] pollè°ƒç”¨updateOffset: topic=%s, partition=%d, offset=%d\n", topic, partition, lastOffset+1);
                            offsetManager.updateOffset(topic, partition, lastOffset + 1);
                            
                            // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: æˆåŠŸæ‹‰å–æ¶ˆæ¯
                            Map<String, String> labels = new HashMap<>();
                            labels.put("topic", topic);
                            labels.put("partition", String.valueOf(partition));
                            metricsCollector.incrementCounter(MetricsCollector.METRIC_CONSUMER_FETCH_SUCCESS, labels);
                            
                            // è®°å½•æ‹‰å–çš„æ¶ˆæ¯æ•°é‡
                            for (int i = 0; i < records.size(); i++) {
                                metricsCollector.incrementCounter("consumer.records.fetched");
                            }
                            
                        } else {
                            System.out.printf("[Poll] topic=%s, partition=%d, fetched=0%n", topic, partition);
                            
                            // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: ç©ºæ‹‰å–
                            Map<String, String> labels = new HashMap<>();
                            labels.put("topic", topic);
                            labels.put("partition", String.valueOf(partition));
                            metricsCollector.incrementCounter("consumer.fetch.empty", labels);
                        }
                        allRecords.addAll(records);
                        break;
                    } catch (Exception e) {
                        System.err.println("[Poll] æ‹‰å–å¼‚å¸¸: " + e.getMessage());
                        
                        // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: æ‹‰å–å¤±è´¥
                        Map<String, String> labels = new HashMap<>();
                        labels.put("topic", topic);
                        labels.put("partition", String.valueOf(partition));
                        labels.put("retry_count", String.valueOf(retryCount));
                        metricsCollector.incrementCounter(MetricsCollector.METRIC_CONSUMER_FETCH_ERROR, labels);
                        
                        retryCount++;
                        if (retryCount >= config.getMaxRetries()) {
                            System.err.println("Failed to fetch from topic=" + topic + ", partition=" + partition + " after " + config.getMaxRetries() + " retries");
                            // é‡è¯•å¤±è´¥ååˆ·æ–°å…ƒæ•°æ® - é”™è¯¯è§¦å‘
                            metadataManager.refreshMetadata(topic, true, false);
                            topicPartitionLeaders.put(topic, metadataManager.getPartitionLeaders(topic));
                            
                            // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: æœ€ç»ˆæ‹‰å–å¤±è´¥
                            metricsCollector.incrementCounter("consumer.fetch.final_failure", labels);
                            
                            // é‡è¯•å¤±è´¥åæŠ›å‡ºå¼‚å¸¸ï¼Œè€Œä¸æ˜¯é™é»˜å¤±è´¥
                            throw new RuntimeException("Failed to fetch from topic=" + topic + ", partition=" + partition + " after " + config.getMaxRetries() + " retries", e);
                        } else {
                            try {
                                Thread.sleep(config.getRetryBackoffMs());
                            } catch (InterruptedException ie) {
                                Thread.currentThread().interrupt();
                                throw new RuntimeException("Interrupted while retrying", ie);
                            }
                        }
                    }
                }
            }
        } catch (Exception e) {
            System.err.println("[Poll] æ‹‰å–è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: " + e.getMessage());
            e.printStackTrace();
            // ä¸è¦é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè€Œæ˜¯è¿”å›ç©ºç»“æœï¼Œè®©æ¶ˆè´¹è€…ç»§ç»­è¿è¡Œ
        } finally {
            long endTime = System.currentTimeMillis();
            long pollLatency = endTime - startTime;
            
            // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: pollå®Œæˆç»Ÿè®¡
            metricsCollector.incrementCounter(MetricsCollector.METRIC_CONSUMER_POLL);
            metricsCollector.recordLatency(MetricsCollector.METRIC_CONSUMER_POLL, pollLatency);
            
            // è®°å½•æ‹‰å–çš„æ¶ˆæ¯æ€»æ•°
            if (!allRecords.isEmpty()) {
                metricsCollector.setGauge("consumer.poll.records_count", allRecords.size());
                metricsCollector.incrementCounter("consumer.poll.success");
            } else {
                metricsCollector.incrementCounter("consumer.poll.empty");
            }
            
            System.out.printf("[Poll] æœ¬æ¬¡æ€»å…±æ‹‰å–æ¶ˆæ¯æ•°: %d\n", allRecords.size());
            System.out.printf("[DEBUG] poll finally, thread=%s, enableAutoCommit=%s\n", Thread.currentThread().getName(), config.isEnableAutoCommit());
            if (config.isEnableAutoCommit()) {
                System.out.println("[DEBUG] poll finallyè‡ªåŠ¨æäº¤offset");
                commitSync();
            } else {
                System.out.println("[DEBUG] poll finallyä¸è‡ªåŠ¨æäº¤offsetï¼Œéœ€è¦æ‰‹åŠ¨è°ƒç”¨commitSync");
            }
        }
        return allRecords;
    }

    @Override
    public void commitSync() {
        System.out.printf("[DEBUG] commitSyncå…¥å£, thread=%s\n", Thread.currentThread().getName());
        if (closed.get()) {
            throw new IllegalStateException("Consumer is closed");
        }

        long startTime = System.currentTimeMillis();
        try {
            offsetManager.commitSync(coordinator.getGenerationId(), coordinator.getMemberId());
            
            // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: æäº¤æˆåŠŸ
            metricsCollector.incrementCounter("consumer.commit.success");
            
        } catch (Exception e) {
            // ğŸ“Š æŒ‡æ ‡åŸ‹ç‚¹: æäº¤å¤±è´¥
            metricsCollector.incrementCounter("consumer.commit.error");
            throw e;
        } finally {
            long endTime = System.currentTimeMillis();
            metricsCollector.incrementCounter(MetricsCollector.METRIC_CONSUMER_COMMIT);
            metricsCollector.recordLatency(MetricsCollector.METRIC_CONSUMER_COMMIT, endTime - startTime);
        }
    }

    @Override
    public void commitAsync() {
        System.out.printf("[DEBUG] commitAsyncå…¥å£, thread=%s\n", Thread.currentThread().getName());
        if (closed.get()) {
            throw new IllegalStateException("Consumer is closed");
        }

        long startTime = System.currentTimeMillis();
        try {
            offsetManager.commitAsync();
        } finally {
            long endTime = System.currentTimeMillis();
            metricsCollector.incrementCounter(MetricsCollector.METRIC_CONSUMER_COMMIT);
            metricsCollector.recordLatency(MetricsCollector.METRIC_CONSUMER_COMMIT, endTime - startTime);
        }
    }

    @Override
    public void close() {
        // å…ˆæäº¤offsetï¼Œå†è®¾ç½®closed=trueï¼Œæœ€åå…³é—­coordinator
        if (!closed.get()) {
            try {
                if (config.isEnableAutoCommit()) {
                    commitSync();
                }
                closed.set(true);
                
                // æ–°å¢ï¼šåœæ­¢å®šæœŸå…ƒæ•°æ®åˆ·æ–°
                stopPeriodicMetadataRefresh();
                
                coordinator.close();
                offsetManager.close();
                
                // æ–°å¢ï¼šå…³é—­MetadataManagerï¼ˆåŒ…æ‹¬è¿æ¥æ± ï¼‰
                if (metadataManager instanceof MetadataManagerImpl) {
                    ((MetadataManagerImpl) metadataManager).close();
                }
                
            } finally {
                // æ¸…ç†èµ„æº
                subscribedTopics = new ArrayList<>();
                topicPartitionLeaders.clear();
            }
        }
    }

    // è·å–æ¶ˆè´¹ç›‘æ§æŒ‡æ ‡
    public double getConsumerQPS() {
        return metricsCollector.getQPS(MetricsCollector.METRIC_CONSUMER_POLL);
    }

    public double getConsumerP99Latency() {
        return metricsCollector.getP99Latency(MetricsCollector.METRIC_CONSUMER_POLL);
    }

    public double getCommitQPS() {
        return metricsCollector.getQPS(MetricsCollector.METRIC_CONSUMER_COMMIT);
    }

    public double getCommitP99Latency() {
        return metricsCollector.getP99Latency(MetricsCollector.METRIC_CONSUMER_COMMIT);
    }
} 